{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Stroke Predict Project\n",
    "\n",
    "This is the final project for DVAE26. In this project I have chosen to create a model for predictive analytics using tabular data. The dataset I decided to use for this project is the stroke dataset from kaggle. The models used for predictions are the decision trees and random forest trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports For Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration and Quality Analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/healthcare-dataset-stroke-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.profile_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_bmi = df['bmi'].median()\n",
    "print(median_bmi)\n",
    "\n",
    "bmi_below_median = df[df['bmi'] <= df['bmi'].median()]\n",
    "bmi_above_median = df[df['bmi'] > df['bmi'].median()]\n",
    "print(bmi_below_median[\"stroke\"].value_counts())\n",
    "print(\"__________________\")\n",
    "print(bmi_above_median[\"stroke\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the unique values in the stroke column\n",
    "print(df['stroke'].unique())\n",
    "\n",
    "# Count the number of occurrences of each class\n",
    "print(df['stroke'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Unnessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['id'],axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "numeric_columns = ['age', 'avg_glucose_level', 'bmi']\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "for i, column in enumerate(numeric_columns):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    sns.boxplot(x=df[column], color=\"#245D5F\")\n",
    "    plt.title(column)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no outliers in the 'age' column, but there are outliers in the 'bmi' and 'avg_glucose_level' columns. I cannot delete them because they are important and it would affect the model. I will therefore utilize scaling and models that are not sensitive to outliers, such as Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['gender','hypertension','ever_married','work_type','Residence_type','smoking_status','heart_disease',]\n",
    "plt.figure(figsize=(20,13))\n",
    "for col in range(len(columns)):\n",
    "    plt.subplot(3,3,col+1)\n",
    "    \n",
    "    sns.countplot(x=df[columns[col]],hue = df['stroke'],palette = \"ch:start=.5,rot=-.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,9))\n",
    "sns.histplot(\n",
    "    df[\"age\"], kde=True,\n",
    "    stat=\"density\", kde_kws=dict(cut=3),color=\"#036272\",\n",
    "    alpha=.6, edgecolor='white')\n",
    "plt.title('Age distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,9))\n",
    "sns.histplot(\n",
    "    df[\"avg_glucose_level\"], kde=True,\n",
    "    stat=\"density\", kde_kws=dict(cut=3),color=\"#036272\",\n",
    "    alpha=.6, edgecolor='white')\n",
    "plt.title('Average blood glucose distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke = dict(df['stroke'].value_counts())\n",
    "\n",
    "fig = px.pie(names = stroke.keys(),values = stroke.values(),title = 'Stroke Occurance',color_discrete_sequence=px.colors.sequential.Aggrnyl)\n",
    "fig.update_traces(textposition='inside', textinfo='percent+label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resamble Unbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display original class distribution\n",
    "print(\"Original class distribution:\")\n",
    "print(df['stroke'].value_counts())\n",
    "\n",
    "# Split the stroke column into 0 and 1\n",
    "df_0 = df[df.iloc[:, -1] == 0]\n",
    "df_1 = df[df.iloc[:, -1] == 1]\n",
    "\n",
    "# Display counts before resampling\n",
    "print(\"\\nClass distribution before resampling:\")\n",
    "print(f\"Class 0 count: {df_0.shape[0]}\")\n",
    "print(f\"Class 1 count: {df_1.shape[0]}\")\n",
    "\n",
    "from sklearn.utils import resample\n",
    "# Resample minority class (1) to match majority class (0)\n",
    "df_1 = resample(df_1, replace=True, n_samples=df_0.shape[0], random_state=42)\n",
    "\n",
    "# Combine the resampled minority class with the majority class\n",
    "df_resampled = pd.concat([df_0, df_1])\n",
    "\n",
    "# Display counts after resampling\n",
    "print(\"\\nClass distribution after resampling:\")\n",
    "print(df_resampled['stroke'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose to use resample instead of SMOTE because it ensures simplicity, avoids generating unrealistic categorical combinations, and works directly with the existing data without additional preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate upsampled data \n",
    "df = np.concatenate((df_0,df_1))\n",
    "\n",
    "#create the balanced dataframe\n",
    "df = pd.DataFrame(df)\n",
    "df.columns = ['gender', 'age', 'hypertension', 'heart_disease', 'ever_married','work_type', 'Residence_type', 'avg_glucose_level', 'bmi','smoking_status', 'stroke']\n",
    "\n",
    "# visualize balanced data \n",
    "\n",
    "plt.figure(figsize=(15,9))\n",
    "sns.countplot(x=df[\"stroke\"],palette=\"dark:salmon_r\")\n",
    "plt.title(\"Stroke\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Age Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define age groups\n",
    "def age_group(age):\n",
    "    if age < 18:\n",
    "        return 'Child'\n",
    "    elif 18 <= age < 35:\n",
    "        return 'Young Adult'\n",
    "    elif 35 <= age < 60:\n",
    "        return 'Adult'\n",
    "    else:\n",
    "        return 'Senior'\n",
    "\n",
    "# Apply function to create a new feature\n",
    "df['age_group'] = df['age'].apply(age_group)\n",
    "\n",
    "# Convert to categorical type for easier handling\n",
    "df['age_group'] = pd.Categorical(df['age_group'], categories=['Child', 'Young Adult', 'Adult', 'Senior'], ordered=True)\n",
    "\n",
    "print(df['age_group'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "columns_to_encode =['age_group', 'gender','ever_married','work_type','Residence_type','smoking_status']\n",
    "\n",
    "for column in columns_to_encode:\n",
    "    df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the 'stroke' column from the rest of the dataset to avoid duplication\n",
    "stroke_col = df['stroke']\n",
    "df = df.drop(columns=['stroke'])\n",
    "\n",
    "# Apply KNNImputer only to the remaining columns\n",
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df_imputed = imputer.fit_transform(df)\n",
    "\n",
    "# Recreate the DataFrame and reattach the 'stroke' column\n",
    "df = pd.DataFrame(df_imputed, columns=df.columns)\n",
    "df['stroke'] = stroke_col\n",
    "\n",
    "# Check for nulls again\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Variable Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution\n",
    "print(\"Target Variable Distribution:\")\n",
    "print(df['stroke'].value_counts(normalize=True))\n",
    "\n",
    "# Visualize the target variable\n",
    "sns.countplot(data=df, x='stroke', palette='Set2')\n",
    "plt.title('Target Variable Distribution')\n",
    "plt.xlabel('Stroke (0 = No, 1 = Yes)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.metrics import confusion_matrix , accuracy_score , precision_score, recall_score, f1_score, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn .ensemble import RandomForestClassifier\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split To>> Features , Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('stroke', axis = 1)\n",
    "y = pd.to_numeric( df['stroke'])\n",
    "\n",
    "# Store the original column names\n",
    "feature_names = x.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "x = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_test , y_train , y_test = train_test_split(x,y,test_size = .20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeClassifier(criterion='entropy')\n",
    "tree_model.fit(x_train,y_train)\n",
    "\n",
    "tree_preds = tree_model.predict(x_test)\n",
    "\n",
    "tree_acc = accuracy_score(y_test, tree_preds)\n",
    "\n",
    "print(f\"Accuracy: {tree_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"n_estimators\": [50, 100, 200], \"max_depth\": [5, 10, 20, None]}\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(rf_model, param_grid=param_grid, n_jobs=-1, cv=5, verbose=1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "rf_preds = grid_search.predict(x_test)\n",
    "rf_acc = accuracy_score(y_test, rf_preds)\n",
    "print(f\"Accuracy: {rf_acc:.3f}\")\n",
    "\n",
    "# Save the best model from grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "joblib.dump(best_model, 'best_rf_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from the best model\n",
    "feature_importances = best_model.feature_importances_\n",
    "\n",
    "# Match feature importances to feature names\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importance\": feature_importances\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df[\"Feature\"], importance_df[\"Importance\"], color='skyblue')\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.title(\"Random Forest Feature Importances\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "# Print the top N features\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestLabelEncoding(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        # Mock dataset\n",
    "        data = {\n",
    "            \"age_group\": [\"Young\", \"Middle-aged\", \"Old\"],\n",
    "            \"gender\": [\"Male\", \"Female\", \"Other\"],\n",
    "            \"ever_married\": [\"No\", \"Yes\", \"No\"],\n",
    "            \"work_type\": [\"Private\", \"Self-employed\", \"Govt_job\"],\n",
    "            \"Residence_type\": [\"Urban\", \"Rural\", \"Urban\"],\n",
    "            \"smoking_status\": [\"Never\", \"Formerly\", \"smokes\"]\n",
    "        }\n",
    "        self.df = pd.DataFrame(data)\n",
    "        self.columns_to_encode = ['age_group', 'gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "\n",
    "    def test_label_encoding(self):\n",
    "        # Apply LabelEncoder\n",
    "        label_encoder = LabelEncoder()\n",
    "        df_encoded = self.df.copy()\n",
    "        for column in self.columns_to_encode:\n",
    "            df_encoded[column] = label_encoder.fit_transform(self.df[column])\n",
    "\n",
    "        # Assertions to test label encoding\n",
    "        for column in self.columns_to_encode:\n",
    "            # Ensure encoded columns have integer types\n",
    "            self.assertTrue(pd.api.types.is_integer_dtype(df_encoded[column]))\n",
    "\n",
    "            # Ensure the number of unique values matches the original\n",
    "            self.assertEqual(len(df_encoded[column].unique()), len(self.df[column].unique()))\n",
    "\n",
    "        # Example check for specific mappings (e.g., \"Male\" -> 1, \"Female\" -> 0, \"Other\" -> 2)\n",
    "        gender_mapping = dict(zip(self.df[\"gender\"].unique(), label_encoder.fit_transform(self.df[\"gender\"].unique())))\n",
    "        self.assertIn(\"Male\", gender_mapping)\n",
    "        self.assertIn(\"Female\", gender_mapping)\n",
    "        self.assertIn(\"Other\", gender_mapping)\n",
    "        self.assertEqual(gender_mapping[\"Other\"], 2)\n",
    "        self.assertEqual(gender_mapping[\"Male\"], 1)\n",
    "        self.assertEqual(gender_mapping[\"Female\"], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for Feature-Target Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestFeatureTargetSplit(unittest.TestCase):\n",
    "    def test_split_features_target(self):\n",
    "        # Mock dataset\n",
    "        data = {\n",
    "            \"age\": [25, 35, 45],\n",
    "            \"gender\": [\"Male\", \"Female\", \"Male\"],\n",
    "            \"bmi\": [24.5, 30.1, 29.4],\n",
    "            \"stroke\": [0, 1,0]\n",
    "        }\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Split features and target\n",
    "        x = df.drop(\"stroke\", axis=1)\n",
    "        y = pd.to_numeric(df[\"stroke\"])\n",
    "        \n",
    "        # Test feature and target dimensions\n",
    "        self.assertEqual(x.shape[0], df.shape[0])\n",
    "        self.assertEqual(len(y), df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestMissingValues(unittest.TestCase):\n",
    "    def test_missing_values(self):\n",
    "        # Mock dataset with missing values\n",
    "        data = {\n",
    "            \"age\": [25, 35, np.nan],  # Missing value\n",
    "            \"gender\": [\"Male\", \"Female\", \"Male\"],\n",
    "            \"bmi\": [24.5, 30.1, 29.4],\n",
    "            \"stroke\": [0, 1, 0]\n",
    "        }\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Check for missing values\n",
    "        self.assertTrue(df.isnull().values.any())\n",
    "        \n",
    "        # Fill missing values\n",
    "        df_filled = df.fillna(df.mean(numeric_only=True))\n",
    "        self.assertFalse(df_filled.isnull().values.any())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestScaling(unittest.TestCase):\n",
    "    def test_scaling(self):\n",
    "        # Mock data after encoding\n",
    "        x = pd.DataFrame({\n",
    "            \"age\": [25, 35, 45],\n",
    "            \"bmi\": [24.5, 30.1, 29.4],\n",
    "            \"gender\": [0, 1, 2]\n",
    "        })\n",
    "        \n",
    "        # Perform scaling\n",
    "        scaler = StandardScaler()\n",
    "        x_scaled = scaler.fit_transform(x)\n",
    "        \n",
    "        # Test that mean is approximately 0 and std is approximately 1\n",
    "        self.assertTrue(np.allclose(x_scaled.mean(axis=0), 0, atol=1e-7))\n",
    "        self.assertTrue(np.allclose(x_scaled.std(axis=0), 1, atol=1e-7))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run all tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Comparison\n",
    "results = {\n",
    "    \"Model\": [\"Decision Tree\", \"Random Forest\"],\n",
    "    \"Accuracy\": [tree_acc, rf_acc],\n",
    "    \"Precision\": [\n",
    "        precision_score(y_test, tree_preds),\n",
    "        precision_score(y_test, rf_preds),\n",
    "    ],\n",
    "    \"Recall\": [\n",
    "        recall_score(y_test, tree_preds),\n",
    "        recall_score(y_test, rf_preds),\n",
    "    ],\n",
    "    \"F1-Score\": [\n",
    "        f1_score(y_test, tree_preds),\n",
    "        f1_score(y_test, rf_preds),\n",
    "    ],\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nModel Comparison:\\n\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, tree_preds))\n",
    "\n",
    "# Generate and display confusion matrix\n",
    "cm = confusion_matrix(y_test, tree_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No Stroke', 'Stroke'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, rf_preds))\n",
    "\n",
    "# Generate and display confusion matrix\n",
    "cm = confusion_matrix(y_test, rf_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No Stroke', 'Stroke'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Repo for Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "# Replace with your actual Hugging Face token\n",
    "hf_token = \"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\"\n",
    "\n",
    "repo_name = \"Asiya-Mohammed/random-forest-model\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the repository dont run if it already exists\n",
    "api.create_repo(repo_id=repo_name, exist_ok=True, private=False, token=hf_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Best Model(Random Forest Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import upload_file\n",
    "\n",
    "# Path to the model file\n",
    "model_path = \"best_rf_model.joblib\"\n",
    "\n",
    "# Upload the model to the repository\n",
    "upload_file(\n",
    "    path_or_fileobj=model_path,              \n",
    "    path_in_repo=\"best_rf_model.joblib\",  \n",
    "    repo_id=repo_name,                     \n",
    "    token=hf_token                           \n",
    ")\n",
    "\n",
    "print(f\"Model uploaded successfully to: https://huggingface.co/{repo_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy ReadMe for Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import upload_file\n",
    "\n",
    "# Path to the readme file\n",
    "readme_path = \"hfREADME.md\"\n",
    "\n",
    "# Upload the readme to the repository\n",
    "upload_file(\n",
    "    path_or_fileobj=readme_path,              \n",
    "    path_in_repo=\"hfREADME.md\",  \n",
    "    repo_id=repo_name,                     \n",
    "    token=hf_token                           \n",
    ")\n",
    "\n",
    "print(f\"Readme uploaded successfully to: https://huggingface.co/{repo_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
